# An√°lise de CSVs com CrewAI

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from scipy import stats
import json
import time
from datetime import datetime
import io
import base64
import os

# Importa√ß√µes para teste de API
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

try:
    from groq import Groq
except ImportError:
    Groq = None

# Importar sistema CrewAI real
from crewai_agents import CSVAnalysisCrew, analyze_csv_with_crewai

# Importar gerador de relat√≥rios
from report_generator import ReportGenerator, generate_pdf_report, generate_word_report

# =============================================================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# =============================================================================

st.set_page_config(
    page_title="üéØ CSV Analysis System - CrewAI",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    .status-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: bold;
        margin: 0.25rem;
    }
    .status-success { background-color: #d4edda; color: #155724; }
    .status-warning { background-color: #fff3cd; color: #856404; }
    .status-danger { background-color: #f8d7da; color: #721c24; }
    .status-info { background-color: #d1ecf1; color: #0c5460; }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# FUN√á√ïES AUXILIARES
# =============================================================================

@st.cache_data
def load_csv_data(uploaded_file):
    """Carrega e processa dados CSV"""
    try:
        df = pd.read_csv(uploaded_file)
        return df, None
    except Exception as e:
        return None, str(e)

def get_data_quality_metrics(df):
    """Calcula m√©tricas de qualidade dos dados"""
    metrics = {
        "total_rows": len(df),
        "total_columns": len(df.columns),
        "duplicates": df.duplicated().sum(),
        "missing_values": df.isnull().sum().sum(),
        "completeness": ((df.count().sum() / (len(df) * len(df.columns))) * 100),
        "numeric_columns": len(df.select_dtypes(include=[np.number]).columns),
        "categorical_columns": len(df.select_dtypes(include=['object']).columns),
        "memory_usage": df.memory_usage(deep=True).sum() / 1024 / 1024  # MB
    }
    return metrics

def create_correlation_heatmap(df):
    """Cria heatmap de correla√ß√£o"""
    numeric_df = df.select_dtypes(include=[np.number])
    if len(numeric_df.columns) < 2:
        return None
    
    corr_matrix = numeric_df.corr()
    
    fig = go.Figure(data=go.Heatmap(
        z=corr_matrix.values,
        x=[str(col) for col in corr_matrix.columns],
        y=[str(col) for col in corr_matrix.columns],
        colorscale='RdBu',
        zmid=0,
        text=np.around(corr_matrix.values, decimals=2),
        texttemplate='%{text}',
        textfont={"size": 10},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title="Matriz de Correla√ß√£o",
        xaxis_title="Vari√°veis",
        yaxis_title="Vari√°veis",
        height=600
    )
    
    return fig

def detect_outliers_iqr(df):
    """Detecta outliers usando m√©todo IQR"""
    numeric_df = df.select_dtypes(include=[np.number])
    outliers_info = {}
    
    for col in numeric_df.columns:
        Q1 = numeric_df[col].quantile(0.25)
        Q3 = numeric_df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = numeric_df[(numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)]
        
        outliers_info[col] = {
            "count": len(outliers),
            "percentage": (len(outliers) / len(numeric_df)) * 100,
            "lower_bound": lower_bound,
            "upper_bound": upper_bound
        }
    
    return outliers_info

def perform_clustering(df, n_clusters=5):
    """Executa clustering K-means"""
    numeric_df = df.select_dtypes(include=[np.number])
    
    if len(numeric_df.columns) < 2:
        return None, None, None
    
    # Identificar linhas sem NaN
    clean_mask = numeric_df.notna().all(axis=1)
    numeric_clean = numeric_df[clean_mask]
    
    if len(numeric_clean) == 0:
        return None, None, None
    
    # Padroniza√ß√£o
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(numeric_clean)
    
    # K-means
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters_clean = kmeans.fit_predict(scaled_data)
    
    # PCA para visualiza√ß√£o
    pca = PCA(n_components=2)
    pca_data = pca.fit_transform(scaled_data)
    
    # Criar array de clusters com tamanho do DataFrame original
    clusters_full = np.full(len(df), -1)  # -1 para linhas com NaN
    clusters_full[clean_mask] = clusters_clean
    
    return clusters_full, pca_data, clean_mask

def create_download_link(df, filename="analysis_results.csv"):
    """Cria link de download para dados"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    return f'<a href="data:file/csv;base64,{b64}" download="{filename}">üì• Download Results</a>'

def process_user_question(question, df, conversation_memory):
    """Processa pergunta do usu√°rio e determina qual agente responder"""
    
    # An√°lise simples para determinar o agente mais adequado
    question_lower = question.lower()
    
    # Palavras-chave para cada agente
    agent_keywords = {
        "Data Validator": ["qualidade", "valida√ß√£o", "duplicata", "faltante", "completo", "integridade", "erro", "problema"],
        "Data Profiler": ["estat√≠stica", "distribui√ß√£o", "m√©dia", "mediana", "desvio", "perfil", "resumo", "descritivo"],
        "Pattern Detective": ["padr√£o", "tend√™ncia", "cluster", "segmento", "grupo", "similar", "correla√ß√£o"],
        "Anomaly Hunter": ["anomalia", "outlier", "estranho", "diferente", "inconsistente", "suspeito"],
        "Relationship Analyst": ["relacionamento", "correla√ß√£o", "associa√ß√£o", "causa", "efeito", "depend√™ncia"],
        "Strategic Synthesizer": ["resumo", "conclus√£o", "recomenda√ß√£o", "estrat√©gia", "insight", "pr√≥ximo passo"]
    }
    
    # Determinar agente baseado nas palavras-chave
    selected_agent = "Strategic Synthesizer"  # padr√£o
    max_score = 0
    
    for agent, keywords in agent_keywords.items():
        score = sum(1 for keyword in keywords if keyword in question_lower)
        if score > max_score:
            max_score = score
            selected_agent = agent
    
    # Gerar resposta baseada no agente selecionado
    response = generate_agent_response(selected_agent, question, df, conversation_memory)
    
    return {
        "agent": selected_agent,
        "response": response
    }

def generate_agent_response(agent_name, question, df, conversation_memory):
    """Gera resposta do agente baseada na pergunta e dados"""
    
    # Resumo dos dados para contexto
    data_summary = f"""
    Dados dispon√≠veis:
    - Total de registros: {len(df):,}
    - Total de colunas: {len(df.columns)}
    - Colunas: {', '.join(df.columns[:10])}{'...' if len(df.columns) > 10 else ''}
    - Valores faltantes: {df.isnull().sum().sum()}
    - Duplicatas: {df.duplicated().sum()}
    """
    
    # Contexto da conversa
    conversation_context = ""
    if conversation_memory:
        recent_messages = conversation_memory[-3:]  # √öltimas 3 mensagens
        conversation_context = "\n".join([f"{msg['role']}: {msg['content']}" for msg in recent_messages])
    
    # Respostas espec√≠ficas por agente
    if agent_name == "Data Validator":
        return f"""üîç **Data Validator** analisando sua pergunta: "{question}"

{data_summary}

**An√°lise de Qualidade dos Dados:**
- Completude geral: {(df.count().sum() / (len(df) * len(df.columns)) * 100):.1f}%
- Colunas com problemas: {len(df.columns[df.isnull().any()])} de {len(df.columns)}
- Registros duplicados: {df.duplicated().sum()}

**Recomenda√ß√µes:**
1. Verificar colunas com valores faltantes
2. Investigar registros duplicados
3. Validar tipos de dados

*Contexto da conversa: {conversation_context[:100]}...*"""

    elif agent_name == "Data Profiler":
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        categorical_cols = df.select_dtypes(include=['object']).columns
        
        return f"""üìä **Data Profiler** analisando sua pergunta: "{question}"

{data_summary}

**Perfil Estat√≠stico:**
- Vari√°veis num√©ricas: {len(numeric_cols)}
- Vari√°veis categ√≥ricas: {len(categorical_cols)}
- Mem√≥ria utilizada: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB

**Insights:**
- Dados mais completos: {df.count().idxmax()} ({df.count().max()} valores)
- Maior variabilidade: {df.std().idxmax() if len(numeric_cols) > 0 else 'N/A'}

*Contexto da conversa: {conversation_context[:100]}...*"""

    elif agent_name == "Pattern Detective":
        return f"""üéØ **Pattern Detective** analisando sua pergunta: "{question}"

{data_summary}

**Padr√µes Identificados:**
- Estrutura dos dados: {len(df)} registros organizados em {len(df.columns)} dimens√µes
- Tipos de dados: {dict(df.dtypes.value_counts())}
- Distribui√ß√£o temporal: {'Sim' if any('date' in col.lower() or 'time' in col.lower() for col in df.columns) else 'N√£o detectada'}

**An√°lise de Segmenta√ß√£o:**
- Potenciais clusters baseados em vari√°veis num√©ricas
- Correla√ß√µes significativas entre vari√°veis

*Contexto da conversa: {conversation_context[:100]}...*"""

    elif agent_name == "Anomaly Hunter":
        numeric_df = df.select_dtypes(include=[np.number])
        outliers_count = 0
        if len(numeric_df.columns) > 0:
            for col in numeric_df.columns:
                Q1 = numeric_df[col].quantile(0.25)
                Q3 = numeric_df[col].quantile(0.75)
                IQR = Q3 - Q1
                outliers = numeric_df[(numeric_df[col] < Q1 - 1.5*IQR) | (numeric_df[col] > Q3 + 1.5*IQR)]
                outliers_count += len(outliers)
        
        return f"""‚ö†Ô∏è **Anomaly Hunter** analisando sua pergunta: "{question}"

{data_summary}

**Anomalias Detectadas:**
- Outliers estat√≠sticos: {outliers_count}
- Valores extremos: {len(df[df.isin([np.inf, -np.inf]).any(axis=1)])}
- Registros inconsistentes: {df.duplicated().sum()}

**Investiga√ß√£o:**
- Verificar se outliers s√£o erros ou casos especiais
- Analisar distribui√ß√£o dos dados
- Identificar poss√≠veis causas das anomalias

*Contexto da conversa: {conversation_context[:100]}...*"""

    elif agent_name == "Relationship Analyst":
        numeric_df = df.select_dtypes(include=[np.number])
        corr_pairs = 0
        if len(numeric_df.columns) > 1:
            corr_matrix = numeric_df.corr()
            corr_pairs = len(corr_matrix[(corr_matrix.abs() > 0.5) & (corr_matrix.abs() < 1.0)].stack())
        
        return f"""üîó **Relationship Analyst** analisando sua pergunta: "{question}"

{data_summary}

**Relacionamentos Identificados:**
- Pares de vari√°veis correlacionadas: {corr_pairs}
- Vari√°veis num√©ricas para an√°lise: {len(numeric_df.columns)}
- Associa√ß√µes categ√≥ricas: {len(df.select_dtypes(include=['object']).columns)}

**An√°lise de Causalidade:**
- Identificar vari√°veis dependentes e independentes
- Mapear relacionamentos significativos
- Sugerir an√°lises de regress√£o

*Contexto da conversa: {conversation_context[:100]}...*"""

    else:  # Strategic Synthesizer
        return f"""üéØ **Strategic Synthesizer** analisando sua pergunta: "{question}"

{data_summary}

**S√≠ntese Estrat√©gica:**
- Dataset com {len(df):,} registros e {len(df.columns)} vari√°veis
- Qualidade geral: {(df.count().sum() / (len(df) * len(df.columns)) * 100):.1f}%
- Pr√≥ximos passos recomendados:
  1. Limpeza de dados se necess√°rio
  2. An√°lise explorat√≥ria detalhada
  3. Modelagem preditiva

**Recomenda√ß√µes de Neg√≥cio:**
- Focar nas vari√°veis mais completas
- Investigar padr√µes de dados faltantes
- Desenvolver estrat√©gia de an√°lise

*Contexto da conversa: {conversation_context[:100]}...*"""

def generate_conversation_report(conversation_memory, df):
    """Gera relat√≥rio da conversa"""
    st.subheader("üìã Relat√≥rio da Conversa")
    
    # Estat√≠sticas da conversa
    total_messages = len(conversation_memory)
    user_questions = len([m for m in conversation_memory if m["role"] == "user"])
    agent_responses = len([m for m in conversation_memory if m["role"] == "assistant"])
    
    # Agentes utilizados
    agents_used = list(set([m.get("agent", "Sistema") for m in conversation_memory if m["role"] == "assistant"]))
    
    # Gerar relat√≥rio
    report = f"""
# Relat√≥rio de An√°lise de Dados - {datetime.now().strftime('%d/%m/%Y %H:%M')}

## Resumo da Conversa
- **Total de mensagens:** {total_messages}
- **Perguntas do usu√°rio:** {user_questions}
- **Respostas dos agentes:** {agent_responses}
- **Agentes utilizados:** {', '.join(agents_used)}

## Dados Analisados
- **Total de registros:** {len(df):,}
- **Total de colunas:** {len(df.columns)}
- **Completude:** {(df.count().sum() / (len(df) * len(df.columns)) * 100):.1f}%
- **Duplicatas:** {df.duplicated().sum()}

## Hist√≥rico da Conversa
"""
    
    for i, message in enumerate(conversation_memory, 1):
        role = "üë§ Usu√°rio" if message["role"] == "user" else f"ü§ñ {message.get('agent', 'Sistema')}"
        report += f"\n### {i}. {role}\n{message['content']}\n"
    
    # Mostrar relat√≥rio
    st.text_area("Relat√≥rio Completo", report, height=400)
    
    # Bot√£o de download
    st.download_button(
        label="üì• Download Relat√≥rio",
        data=report,
        file_name=f"relatorio_conversa_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain"
    )

def save_conversation_to_file(conversation_memory):
    """Salva conversa em arquivo"""
    conversation_data = {
        "timestamp": datetime.now().isoformat(),
        "conversation": conversation_memory,
        "summary": {
            "total_messages": len(conversation_memory),
            "user_messages": len([m for m in conversation_memory if m["role"] == "user"]),
            "agent_messages": len([m for m in conversation_memory if m["role"] == "assistant"])
        }
    }
    
    # Converter para JSON
    json_data = json.dumps(conversation_data, indent=2, ensure_ascii=False)
    
    # Bot√£o de download
    st.download_button(
        label="üì• Download Conversa (JSON)",
        data=json_data,
        file_name=f"conversa_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json"
    )

# =============================================================================
# INTERFACE PRINCIPAL
# =============================================================================

def main():
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1>üìä CSV Analysis System with CrewAI</h1>
        <p>Sistema completo de an√°lise de dados CSV com agentes especializados em IA</p>
    </div>
    """, unsafe_allow_html=True)
    
    # =============================================================================
    # BARRA LATERAL - CONFIGURA√á√ïES E CONTROLES
    # =============================================================================
    
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # 1. Sele√ß√£o de API
        st.subheader("üîë API de IA")
        api_provider = st.selectbox(
            "Escolha o provedor de IA:",
            ["OpenAI", "GROQ", "Gemini", "Claude", "Perplexity"],
            help="Selecione qual API de IA usar para an√°lise"
        )
        
        # Configura√ß√µes espec√≠ficas por API
        if api_provider == "OpenAI":
            api_key = st.text_input(
                "Chave da API OpenAI:",
                type="password",
                value=os.getenv("OPENAI_API_KEY", ""),
                help="Insira sua chave da API OpenAI"
            )
        elif api_provider == "GROQ":
            api_key = st.text_input(
                "Chave da API GROQ:",
                type="password",
                value=os.getenv("GROQ_API_KEY", ""),
                help="Insira sua chave da API GROQ"
            )
        elif api_provider == "Gemini":
            api_key = st.text_input(
                "Chave da API Gemini:",
                type="password",
                help="Insira sua chave da API Google Gemini"
            )
        elif api_provider == "Claude":
            api_key = st.text_input(
                "Chave da API Claude:",
                type="password",
                help="Insira sua chave da API Anthropic Claude"
            )
        elif api_provider == "Perplexity":
            api_key = st.text_input(
                "Chave da API Perplexity:",
                type="password",
                help="Insira sua chave da API Perplexity"
            )
        
        # Salvar configura√ß√£o da API
        if st.button("üíæ Salvar Configura√ß√£o da API"):
            if api_key:
                # Atualizar vari√°veis de ambiente
                if api_provider == "OpenAI":
                    os.environ["OPENAI_API_KEY"] = api_key
                elif api_provider == "GROQ":
                    os.environ["GROQ_API_KEY"] = api_key
                st.success(f"‚úÖ Configura√ß√£o da API {api_provider} salva!")
            else:
                st.error("‚ùå Por favor, insira uma chave de API v√°lida")
        
        # Teste de API
        if st.button("üß™ Testar API", help="Testa se a chave da API est√° funcionando"):
            if api_key:
                with st.spinner("üîÑ Testando conex√£o com a API..."):
                    try:
                        # Teste simples da API
                        if api_provider == "OpenAI":
                            if OpenAI is None:
                                st.error("‚ùå Biblioteca 'openai' n√£o est√° instalada. Execute: pip install openai")
                            else:
                                client = OpenAI(api_key=api_key)
                                # Teste simples - listar modelos
                                models = client.models.list()
                                st.success("‚úÖ Chave da API OpenAI est√° funcionando!")
                                st.balloons()
                        elif api_provider == "GROQ":
                            if Groq is None:
                                st.error("‚ùå Biblioteca 'groq' n√£o est√° instalada. Execute: pip install groq")
                            else:
                                client = Groq(api_key=api_key)
                                # Teste simples - listar modelos
                                models = client.models.list()
                                st.success("‚úÖ Chave da API GROQ est√° funcionando!")
                                st.balloons()
                        else:
                            st.info(f"‚ÑπÔ∏è Teste para {api_provider} ainda n√£o implementado")
                    except Exception as e:
                        st.error(f"‚ùå Erro ao testar API: {str(e)}")
            else:
                st.error("‚ùå Por favor, insira uma chave de API primeiro")
        
        st.divider()
        
        # 2. Carregamento de arquivos CSV
        st.subheader("üìÅ Carregar Arquivos CSV")
        
        uploaded_files = st.file_uploader(
            "Selecione um ou mais arquivos CSV:",
            type=['csv'],
            accept_multiple_files=True,
            help="Voc√™ pode carregar m√∫ltiplos arquivos CSV para an√°lise"
        )
        
        if uploaded_files:
            st.success(f"‚úÖ {len(uploaded_files)} arquivo(s) carregado(s)")
            
            # Listar arquivos carregados
            for i, file in enumerate(uploaded_files):
                st.write(f"üìÑ {i+1}. {file.name}")
        
        st.divider()
        
        # 3. Identifica√ß√£o da an√°lise
        st.subheader("üè∑Ô∏è Identifica√ß√£o da An√°lise")
        
        analysis_name = st.text_input(
            "Nome da an√°lise:",
            value="An√°lise CSV - " + datetime.now().strftime("%Y-%m-%d %H:%M"),
            help="D√™ um nome descritivo para esta an√°lise"
        )
        
        analysis_description = st.text_area(
            "Descri√ß√£o da an√°lise:",
            placeholder="Descreva o objetivo e contexto desta an√°lise...",
            help="Adicione uma descri√ß√£o detalhada do que ser√° analisado"
        )
        
        # Salvar identifica√ß√£o
        if st.button("üíæ Salvar Identifica√ß√£o"):
            if analysis_name:
                st.session_state['analysis_name'] = analysis_name
                st.session_state['analysis_description'] = analysis_description
                st.success("‚úÖ Identifica√ß√£o da an√°lise salva!")
            else:
                st.error("‚ùå Por favor, insira um nome para a an√°lise")
        
        st.divider()
        
        # 4. Download de relat√≥rios
        st.subheader("üì• Download de Relat√≥rios")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üìÑ PDF", use_container_width=True):
                if uploaded_files and len(uploaded_files) > 0:
                    try:
                        # Carregar dados
                        df, error = load_csv_data(uploaded_files[0])
                        if not error:
                            # Gerar PDF
                            analysis_name = st.session_state.get('analysis_name', 'An√°lise CSV')
                            analysis_description = st.session_state.get('analysis_description', '')
                            
                            pdf_data = generate_pdf_report(df, analysis_name, analysis_description)
                            
                            # Criar bot√£o de download
                            st.download_button(
                                label="üì• Download PDF",
                                data=pdf_data,
                                file_name=f"{analysis_name.replace(' ', '_')}.pdf",
                                mime="application/pdf"
                            )
                            st.success("‚úÖ Relat√≥rio PDF gerado!")
                        else:
                            st.error(f"‚ùå Erro ao carregar dados: {error}")
                    except Exception as e:
                        st.error(f"‚ùå Erro ao gerar PDF: {str(e)}")
                else:
                    st.warning("‚ö†Ô∏è Carregue um arquivo CSV primeiro")
        
        with col2:
            if st.button("üìù Word", use_container_width=True):
                if uploaded_files and len(uploaded_files) > 0:
                    try:
                        # Carregar dados
                        df, error = load_csv_data(uploaded_files[0])
                        if not error:
                            # Gerar Word
                            analysis_name = st.session_state.get('analysis_name', 'An√°lise CSV')
                            analysis_description = st.session_state.get('analysis_description', '')
                            
                            word_data = generate_word_report(df, analysis_name, analysis_description)
                            
                            # Criar bot√£o de download
                            st.download_button(
                                label="üì• Download Word",
                                data=word_data,
                                file_name=f"{analysis_name.replace(' ', '_')}.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                            st.success("‚úÖ Relat√≥rio Word gerado!")
                        else:
                            st.error(f"‚ùå Erro ao carregar dados: {error}")
                    except Exception as e:
                        st.error(f"‚ùå Erro ao gerar Word: {str(e)}")
                else:
                    st.warning("‚ö†Ô∏è Carregue um arquivo CSV primeiro")
        
        # Informa√ß√µes da sess√£o
        st.divider()
        st.subheader("‚ÑπÔ∏è Informa√ß√µes da Sess√£o")
        
        if 'analysis_name' in st.session_state:
            st.write(f"**An√°lise:** {st.session_state['analysis_name']}")
        
        if uploaded_files:
            st.write(f"**Arquivos:** {len(uploaded_files)}")
        
        st.write(f"**API:** {api_provider}")
        st.write(f"**Data:** {datetime.now().strftime('%d/%m/%Y %H:%M')}")
        
        # Configura√ß√µes do Chat
        if uploaded_files and len(uploaded_files) > 0:
            st.divider()
            st.subheader("üí¨ Configura√ß√µes do Chat")
            
            # Configura√ß√µes de mem√≥ria
            st.markdown("**üß† Configura√ß√µes de Mem√≥ria:**")
            enable_memory = st.checkbox("Ativar mem√≥ria de conversas", value=True, help="Os agentes lembrar√£o das perguntas anteriores")
            memory_duration = st.selectbox("Dura√ß√£o da mem√≥ria", ["Sess√£o atual", "24 horas", "7 dias"], help="Por quanto tempo manter a mem√≥ria")
            
            # Configura√ß√µes de relat√≥rio
            st.markdown("**üìã Configura√ß√µes de Relat√≥rio:**")
            auto_report = st.checkbox("Gerar relat√≥rio autom√°tico", value=True, help="Relat√≥rio ser√° gerado ao final da conversa")
            report_format = st.selectbox("Formato do relat√≥rio", ["PDF", "Word", "Texto"], help="Formato do relat√≥rio final")
    
    # =============================================================================
    # √ÅREA PRINCIPAL DA APLICA√á√ÉO
    # =============================================================================
    
    # Conte√∫do principal
    if uploaded_files and len(uploaded_files) > 0:
        # Carregar dados do primeiro arquivo
        df, error = load_csv_data(uploaded_files[0])
        
        if error:
            st.error(f"‚ùå Erro ao carregar arquivo: {error}")
            return
        
        # Tabs principais - apenas Overview e Chat
        tab1, tab2 = st.tabs([
            "üìä Overview", 
            "üí¨ Chat com Agentes IA"
        ])
        
        # TAB 1: OVERVIEW
        with tab1:
            show_overview_tab(df)
        
        # TAB 2: CHAT COM AGENTES IA
        with tab2:
            show_chat_interface(df)
    
    else:
        # P√°gina inicial
        show_welcome_page()

# =============================================================================
# FUN√á√ïES DAS TABS
# =============================================================================

def show_welcome_page():
    """Mostra p√°gina de boas-vindas"""
    # T√≠tulo principal em uma √∫nica linha
    st.markdown("""
    <div style="text-align: center; margin-bottom: 2rem;">
        <h1>üéØ Bem-vindo ao Sistema de An√°lise CSV com IA</h1>
        <p style="font-size: 1.2em; color: #666;">Converse com agentes especializados para analisar seus dados</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Se√ß√µes lado a lado
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### ü§ñ Agentes Especializados:
        - **üîç Data Validator** - Valida√ß√£o e qualidade dos dados
        - **üìä Data Profiler** - Perfilamento estat√≠stico detalhado
        - **üéØ Pattern Detective** - Detec√ß√£o de padr√µes e clustering
        - **‚ö†Ô∏è Anomaly Hunter** - Detec√ß√£o de anomalias e outliers
        - **üîó Relationship Analyst** - An√°lise de correla√ß√µes
        - **üéØ Strategic Synthesizer** - S√≠ntese estrat√©gica
        """)
    
    with col2:
        st.markdown("""
        ### üí¨ Como usar:
        1. Fa√ßa upload do seu arquivo CSV na barra lateral
        2. Configure sua chave de API de IA
        3. V√° para a aba "Chat com Agentes IA"
        4. Fa√ßa perguntas sobre seus dados
        5. Receba an√°lises especializadas em tempo real
        """)
    
    with col3:
        st.markdown("""
        ### üöÄ Funcionalidades:
        - ‚úÖ Chat interativo com agentes de IA
        - ‚úÖ Mem√≥ria de conversas
        - ‚úÖ Relat√≥rios autom√°ticos
        - ‚úÖ An√°lise em tempo real
        - ‚úÖ Respostas especializadas
        - ‚úÖ Exporta√ß√£o de conversas
        """)
    
    # Se√ß√£o de demonstra√ß√£o
    st.divider()
    st.markdown("""
    ### üé¨ Demonstra√ß√£o R√°pida
    
    **Exemplo de perguntas que voc√™ pode fazer:**
    
    - "Qual a qualidade dos meus dados?"
    - "Existem anomalias nos dados?"
    - "Quais padr√µes voc√™ consegue identificar?"
    - "Como est√£o as correla√ß√µes entre as vari√°veis?"
    - "Me d√™ um resumo estrat√©gico dos dados"
    
    **Os agentes ir√£o:**
    - Analisar seus dados em tempo real
    - Lembrar do contexto da conversa
    - Fornecer insights especializados
    - Gerar relat√≥rios personalizados
        """)

def show_overview_tab(df):
    """Mostra overview geral dos dados"""
    st.header("üìä Vis√£o Geral dos Dados")
    
    # M√©tricas gerais
    metrics = get_data_quality_metrics(df)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìã Total de Linhas", f"{metrics['total_rows']:,}")
    with col2:
        st.metric("üìä Total de Colunas", metrics['total_columns'])
    with col3:
        st.metric("üéØ Completude", f"{metrics['completeness']:.1f}%")
    with col4:
        st.metric("üíæ Tamanho (MB)", f"{metrics['memory_usage']:.2f}")
    
    st.divider()
    
    # Preview dos dados
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üîç Preview dos Dados")
        st.dataframe(df.head(10), width='stretch')
    
    with col2:
        st.subheader("üìà Tipos de Dados")
        dtype_counts = df.dtypes.value_counts()
        fig = px.pie(
            values=dtype_counts.values,
            names=[str(dtype) for dtype in dtype_counts.index],
            title="Distribui√ß√£o dos Tipos de Dados"
        )
        st.plotly_chart(fig, width='stretch')
    
    # Informa√ß√µes detalhadas
    st.subheader("üìã Informa√ß√µes Detalhadas das Colunas")
    
    col_info = []
    for col in df.columns:
        col_info.append({
            "Coluna": col,
            "Tipo": str(df[col].dtype),
            "N√£o Nulos": df[col].count(),
            "Nulos": df[col].isnull().sum(),
            "% Completo": f"{(df[col].count() / len(df) * 100):.1f}%",
            "√önicos": df[col].nunique()
        })
    
    info_df = pd.DataFrame(col_info)
    st.dataframe(info_df, width='stretch')


def show_chat_interface(df):
    """Interface de chat com agentes CrewAI"""
    st.header("üí¨ Chat com Agentes de IA")
    
    # Inicializar sess√£o de chat se n√£o existir
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    if 'conversation_memory' not in st.session_state:
        st.session_state.conversation_memory = []
    
    # Informa√ß√µes sobre os agentes dispon√≠veis
    st.markdown("""
    ### ü§ñ Agentes Especializados Dispon√≠veis:
    
    - **üîç Data Validator** - Valida√ß√£o e qualidade dos dados
    - **üìä Data Profiler** - Perfilamento estat√≠stico detalhado  
    - **üéØ Pattern Detective** - Detec√ß√£o de padr√µes e clustering
    - **‚ö†Ô∏è Anomaly Hunter** - Detec√ß√£o de anomalias e outliers
    - **üîó Relationship Analyst** - An√°lise de correla√ß√µes
    - **üéØ Strategic Synthesizer** - S√≠ntese estrat√©gica
    """)
    
    # √Årea de chat
    chat_container = st.container()
    
    with chat_container:
        # Mostrar hist√≥rico de chat
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                with st.chat_message("user"):
                    st.write(message["content"])
            else:
                with st.chat_message("assistant"):
                    st.write(message["content"])
                    if "agent" in message:
                        st.caption(f"ü§ñ Resposta do {message['agent']}")
    
    # Input de chat
    user_input = st.chat_input("Digite sua pergunta sobre os dados...")
    
    if user_input:
        # Adicionar mensagem do usu√°rio ao hist√≥rico
        st.session_state.chat_history.append({
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now().isoformat()
        })
        
        # Adicionar √† mem√≥ria da conversa
        st.session_state.conversation_memory.append({
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now().isoformat()
        })
        
        # Processar pergunta com agentes
        with st.spinner("ü§ñ Agentes analisando sua pergunta..."):
            try:
                # Determinar qual agente √© mais adequado para a pergunta
                agent_response = process_user_question(user_input, df, st.session_state.conversation_memory)
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": agent_response["response"],
                    "agent": agent_response["agent"],
                    "timestamp": datetime.now().isoformat()
                })
                
                # Adicionar √† mem√≥ria da conversa
                st.session_state.conversation_memory.append({
                    "role": "assistant",
                    "content": agent_response["response"],
                    "agent": agent_response["agent"],
                    "timestamp": datetime.now().isoformat()
                })
                
                # Mostrar resposta
                with st.chat_message("assistant"):
                    st.write(agent_response["response"])
                    st.caption(f"ü§ñ Resposta do {agent_response['agent']}")
                
            except Exception as e:
                error_msg = f"‚ùå Erro ao processar pergunta: {str(e)}"
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": error_msg,
                    "agent": "Sistema",
                    "timestamp": datetime.now().isoformat()
                })
                
                with st.chat_message("assistant"):
                    st.write(error_msg)
                    st.caption("ü§ñ Resposta do Sistema")
    
    # Controles do chat
    st.divider()
        
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üóëÔ∏è Limpar Chat", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.conversation_memory = []
            st.rerun()
    
    with col2:
        if st.button("üìã Gerar Relat√≥rio", use_container_width=True):
            if st.session_state.conversation_memory:
                generate_conversation_report(st.session_state.conversation_memory, df)
            else:
                st.warning("‚ö†Ô∏è Nenhuma conversa para gerar relat√≥rio")
    
    with col3:
        if st.button("üíæ Salvar Conversa", use_container_width=True):
            if st.session_state.conversation_memory:
                save_conversation_to_file(st.session_state.conversation_memory)
            else:
                st.warning("‚ö†Ô∏è Nenhuma conversa para salvar")
    
    # Estat√≠sticas da conversa
    if st.session_state.chat_history:
        st.divider()
        st.subheader("üìä Estat√≠sticas da Conversa")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üí¨ Total de Mensagens", len(st.session_state.chat_history))
        
        with col2:
            user_messages = len([m for m in st.session_state.chat_history if m["role"] == "user"])
            st.metric("üë§ Perguntas do Usu√°rio", user_messages)
        
        with col3:
            agent_messages = len([m for m in st.session_state.chat_history if m["role"] == "assistant"])
            st.metric("ü§ñ Respostas dos Agentes", agent_messages)
        
        with col4:
            unique_agents = len(set([m.get("agent", "Sistema") for m in st.session_state.chat_history if m["role"] == "assistant"]))
            st.metric("üé≠ Agentes Utilizados", unique_agents)


# =============================================================================
# CONFIGURA√á√ïES AVAN√áADAS
# =============================================================================

def show_advanced_settings():
    """Mostra configura√ß√µes avan√ßadas"""
    with st.sidebar.expander("üõ†Ô∏è Configura√ß√µes dos Agentes"):
        
        st.markdown("### ü§ñ Data Validator")
        data_validator_config = {
            "quality_threshold": st.slider("Threshold de Qualidade", 0.5, 1.0, 0.9),
            "duplicate_check": st.checkbox("Verificar Duplicatas", value=True),
            "encoding_check": st.checkbox("Verificar Encoding", value=True)
        }
        
        st.markdown("### üìä Data Profiler") 
        data_profiler_config = {
            "include_correlations": st.checkbox("Incluir Correla√ß√µes", value=True),
            "histogram_bins": st.slider("Bins do Histograma", 10, 100, 30),
            "percentiles": st.multiselect("Percentis", [10, 25, 50, 75, 90, 95], default=[25, 50, 75])
        }
        
        st.markdown("### üîç Pattern Detective")
        pattern_config = {
            "clustering_method": st.selectbox("M√©todo de Clustering", ["K-means", "Hierarchical", "DBSCAN"]),
            "pca_components": st.slider("Componentes PCA", 2, 10, 2),
            "random_state": st.number_input("Random State", value=42)
        }
        
        return {
            "data_validator": data_validator_config,
            "data_profiler": data_profiler_config, 
            "pattern_detective": pattern_config
        }

# =============================================================================
# FUNCIONALIDADES EXTRAS
# =============================================================================

def create_executive_dashboard(df):
    """Cria dashboard executivo"""
    st.subheader("üéØ Dashboard Executivo")
    
    metrics = get_data_quality_metrics(df)
    
    # KPIs principais
    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    
    with kpi1:
        delta_quality = metrics['completeness'] - 90
        st.metric(
            "üìä Qualidade dos Dados",
            f"{metrics['completeness']:.1f}%",
            delta=f"{delta_quality:+.1f}%"
        )
    
    with kpi2:
        st.metric(
            "üìã Volume de Dados", 
            f"{metrics['total_rows']:,}",
            delta="Linhas"
        )
    
    with kpi3:
        st.metric(
            "‚ö†Ô∏è Problemas Identificados",
            metrics['duplicates'] + metrics['missing_values'],
            delta="Issues"
        )
    
    with kpi4:
        efficiency = 100 - ((metrics['duplicates'] + metrics['missing_values']) / metrics['total_rows'] * 100)
        st.metric(
            "‚ö° Efici√™ncia",
            f"{efficiency:.1f}%",
            delta="Score"
        )

def show_real_time_monitoring():
    """Mostra monitoramento em tempo real"""
    st.subheader("üì° Monitoramento em Tempo Real")
    
    # Placeholder para dados em tempo real
    placeholder = st.empty()
    
    if st.button("‚ñ∂Ô∏è Iniciar Monitoramento"):
        for i in range(10):
            with placeholder.container():
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # Simular dados em tempo real
                    quality_score = 90 + np.random.normal(0, 5)
                    st.metric("Qualidade Atual", f"{quality_score:.1f}%")
                
                with col2:
                    anomalies = np.random.poisson(2)
                    st.metric("Anomalias Detectadas", anomalies)
                
                with col3:
                    processing_time = np.random.uniform(0.5, 2.0)
                    st.metric("Tempo de Processamento", f"{processing_time:.2f}s")
                
                # Gr√°fico de linha em tempo real
                times = pd.date_range(start='now', periods=20, freq='1min')
                values = 90 + np.random.normal(0, 3, 20)
                
                fig = px.line(
                    x=times, 
                    y=values,
                    title="Qualidade dos Dados - √öltimas 20 medi√ß√µes"
                )
                st.plotly_chart(fig, width='stretch')
                
                time.sleep(2)

# =============================================================================
# INICIALIZA√á√ÉO DA APLICA√á√ÉO
# =============================================================================

if __name__ == "__main__":
    main()
