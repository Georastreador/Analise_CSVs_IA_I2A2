# M√≥dulo de Chat com IA - Integra√ß√£o com APIs
# Estilo ChatGPT com an√°lise de dados

import streamlit as st
import pandas as pd
import json
from datetime import datetime
import os
import base64

# Importa√ß√µes para APIs de IA
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

try:
    from groq import Groq
except ImportError:
    Groq = None

try:
    import google.generativeai as genai
except ImportError:
    genai = None

try:
    from anthropic import Anthropic
except ImportError:
    Anthropic = None

try:
    import requests
    # Perplexity n√£o tem biblioteca oficial, usaremos requests
    Perplexity = "requests_available"
except ImportError:
    Perplexity = None

class ChatAI:
    def __init__(self, api_provider="OpenAI", api_key=None):
        self.api_provider = api_provider
        self.api_key = api_key
        self.client = None
        self.setup_client()
    
    def setup_client(self):
        """Configura o cliente da API selecionada"""
        if not self.api_key:
            return
        
        try:
            if self.api_provider == "OpenAI" and OpenAI:
                self.client = OpenAI(api_key=self.api_key)
            elif self.api_provider == "GROQ" and Groq:
                self.client = Groq(api_key=self.api_key)
            elif self.api_provider == "Gemini" and genai:
                genai.configure(api_key=self.api_key)
                self.client = genai.GenerativeModel('gemini-2.5-flash-lite-preview-09-2025')
            elif self.api_provider == "Claude" and Anthropic:
                self.client = Anthropic(api_key=self.api_key)
            elif self.api_provider == "Perplexity" and Perplexity:
                self.client = {"api_key": self.api_key}
        except Exception as e:
            st.error(f"Erro ao configurar cliente {self.api_provider}: {str(e)}")
    
    def analyze_data_context(self, df, analysis_name="An√°lise CSV"):
        """Gera contexto sobre os dados para a IA"""
        if df is None:
            return "Nenhum dado carregado."
        
        # An√°lise de correla√ß√£o
        correlation_analysis = self.get_correlation_analysis(df)
        
        context = f"""
        CONTEXTO DA AN√ÅLISE:
        - Nome da an√°lise: {analysis_name}
        - Data/hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
        
        CONTEXTO DOS DADOS:
        - Total de registros: {len(df):,}
        - Total de colunas: {len(df.columns)}
        - Colunas: {', '.join(df.columns.tolist())}
        - Tipos de dados: {dict(df.dtypes)}
        - Valores faltantes: {df.isnull().sum().sum()}
        - Duplicatas: {df.duplicated().sum()}
        
        ESTAT√çSTICAS B√ÅSICAS:
        {df.describe().to_string()}
        
        AN√ÅLISE DE CORRELA√á√ÉO:
        {correlation_analysis}
        
        PRIMEIRAS 5 LINHAS:
        {df.head().to_string()}
        """
        return context
    
    def get_correlation_analysis(self, df):
        """Analisa correla√ß√µes entre vari√°veis num√©ricas"""
        try:
            # Selecionar apenas colunas num√©ricas
            numeric_cols = df.select_dtypes(include=['number']).columns
            
            if len(numeric_cols) < 2:
                return "N√£o h√° vari√°veis num√©ricas suficientes para an√°lise de correla√ß√£o (m√≠nimo 2)."
            
            # Calcular matriz de correla√ß√£o
            corr_matrix = df[numeric_cols].corr()
            
            # Encontrar correla√ß√µes significativas (|r| > 0.5)
            significant_correlations = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_value = corr_matrix.iloc[i, j]
                    if abs(corr_value) > 0.5:
                        col1 = corr_matrix.columns[i]
                        col2 = corr_matrix.columns[j]
                        strength = "forte" if abs(corr_value) > 0.7 else "moderada"
                        direction = "positiva" if corr_value > 0 else "negativa"
                        significant_correlations.append(
                            f"- {col1} ‚Üî {col2}: {corr_value:.3f} (correla√ß√£o {strength} {direction})"
                        )
            
            # Resumo da an√°lise
            analysis = f"""
        Vari√°veis num√©ricas analisadas: {len(numeric_cols)}
        Colunas: {', '.join(numeric_cols.tolist())}
        
        CORRELA√á√ïES SIGNIFICATIVAS (|r| > 0.5):
        """
            
            if significant_correlations:
                analysis += "\n".join(significant_correlations)
            else:
                analysis += "Nenhuma correla√ß√£o significativa encontrada (|r| > 0.5)."
            
            # Adicionar interpreta√ß√£o
            analysis += f"""
        
        INTERPRETA√á√ÉO:
        - Correla√ß√£o forte: |r| > 0.7
        - Correla√ß√£o moderada: 0.5 < |r| ‚â§ 0.7
        - Correla√ß√£o fraca: |r| ‚â§ 0.5
        - Valores pr√≥ximos de 1 indicam correla√ß√£o positiva forte
        - Valores pr√≥ximos de -1 indicam correla√ß√£o negativa forte
        - Valores pr√≥ximos de 0 indicam pouca ou nenhuma correla√ß√£o linear
            """
            
            return analysis
            
        except Exception as e:
            return f"Erro ao calcular correla√ß√µes: {str(e)}"
    
    def generate_response(self, user_message, df=None, analysis_name="An√°lise CSV"):
        """Gera resposta da IA baseada na mensagem do usu√°rio"""
        if not self.client:
            return "‚ùå Cliente de IA n√£o configurado. Verifique sua chave de API."
        
        try:
            # Contexto dos dados
            data_context = self.analyze_data_context(df, analysis_name)
            
            # Prompt do sistema
            system_prompt = f"""
            Voc√™ √© um assistente especializado em an√°lise de dados. 
            Responda de forma clara, objetiva e √∫til sobre os dados fornecidos.
            
            {data_context}
            
            Instru√ß√µes:
            - Seja conciso mas informativo
            - Use emojis quando apropriado
            - Sugira visualiza√ß√µes quando relevante
            - Identifique padr√µes e insights
            - Responda em portugu√™s brasileiro
            
            AN√ÅLISE DE CORRELA√á√ÉO:
            - Quando perguntado sobre correla√ß√µes, use os dados de correla√ß√£o fornecidos no contexto
            - Explique o significado das correla√ß√µes encontradas
            - Mencione que correla√ß√£o n√£o implica causalidade
            - Sugira interpreta√ß√µes pr√°ticas das correla√ß√µes
            - Se n√£o houver correla√ß√µes significativas, explique o que isso significa
            """
            
            # Preparar mensagens
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]
            
            # Fazer chamada para a API
            if self.api_provider == "OpenAI":
                response = self.client.chat.completions.create(
                    model="gpt-4",
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7
                )
                return response.choices[0].message.content
            
            elif self.api_provider == "GROQ":
                response = self.client.chat.completions.create(
                    model="llama-3.1-8b-instant",
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7
                )
                return response.choices[0].message.content
            
            elif self.api_provider == "Gemini":
                # Converter mensagens para formato Gemini
                prompt = f"{system_prompt}\n\n{user_message}"
                response = self.client.generate_content(prompt)
                return response.text
            
            elif self.api_provider == "Claude":
                response = self.client.messages.create(
                    model="claude-3-sonnet-20240229",
                    max_tokens=1000,
                    temperature=0.7,
                    messages=[
                        {"role": "user", "content": f"{system_prompt}\n\n{user_message}"}
                    ]
                )
                return response.content[0].text
            
            elif self.api_provider == "Perplexity":
                # Perplexity API via requests
                import requests
                headers = {
                    "Authorization": f"Bearer {self.client['api_key']}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "llama-3.1-sonar-small-128k-online",
                    "messages": messages,
                    "max_tokens": 1000,
                    "temperature": 0.7
                }
                response = requests.post(
                    "https://api.perplexity.ai/chat/completions",
                    headers=headers,
                    json=data
                )
                if response.status_code == 200:
                    return response.json()["choices"][0]["message"]["content"]
                else:
                    return f"‚ùå Erro Perplexity: {response.status_code} - {response.text}"
            
        except Exception as e:
            return f"‚ùå Erro ao gerar resposta: {str(e)}"
    
    def suggest_questions(self, df):
        """Sugere perguntas baseadas nos dados"""
        if df is None:
            return [
                "Carregue um arquivo CSV para come√ßar a an√°lise",
                "Que tipo de insights voc√™ gostaria de obter?",
                "Precisa de ajuda com alguma an√°lise espec√≠fica?"
            ]
        
        suggestions = [
            "üìä Quais s√£o os principais insights destes dados?",
            "üîç Existem padr√µes ou tend√™ncias interessantes?",
            "üìà Existe correla√ß√£o entre as vari√°veis?",
            "‚ö†Ô∏è H√° problemas de qualidade nos dados?",
            "üìà Como posso visualizar melhor estes dados?",
            "üéØ Que recomenda√ß√µes voc√™ tem para an√°lise?",
            "üìã Resuma as principais caracter√≠sticas dos dados"
        ]
        
        # Adicionar sugest√µes espec√≠ficas baseadas nos dados
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            suggestions.append(f"üìä Analise a correla√ß√£o entre {', '.join(numeric_cols[:3])}")
        
        categorical_cols = df.select_dtypes(include=['object']).columns
        if len(categorical_cols) > 0:
            suggestions.append(f"üìã Quais s√£o as categorias mais comuns em {categorical_cols[0]}?")
        
        return suggestions

def export_conversations_to_json(messages, analysis_name="An√°lise CSV"):
    """Exporta as conversas para formato JSON"""
    try:
        # Criar estrutura de dados para exporta√ß√£o
        export_data = {
            "metadata": {
                "analysis_name": analysis_name,
                "export_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "total_messages": len(messages),
                "export_format": "JSON"
            },
            "conversation": []
        }
        
        # Adicionar mensagens √† conversa
        for i, message in enumerate(messages):
            export_data["conversation"].append({
                "message_id": i + 1,
                "role": message["role"],
                "content": message["content"],
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
        
        # Converter para JSON
        json_data = json.dumps(export_data, ensure_ascii=False, indent=2)
        
        return json_data
        
    except Exception as e:
        return f"Erro ao exportar conversas: {str(e)}"

def show_chat_interface_v2(api_provider, api_key, df, analysis_name="An√°lise CSV"):
    """Interface de chat melhorada estilo ChatGPT"""
    
    # Inicializar chat AI
    if "chat_ai" not in st.session_state:
        st.session_state.chat_ai = ChatAI(api_provider, api_key)
    
    # Atualizar cliente se necess√°rio
    if st.session_state.chat_ai.api_key != api_key:
        st.session_state.chat_ai = ChatAI(api_provider, api_key)
    
    # Container do chat
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    # Inicializar hist√≥rico
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ===== CAMPO DE INPUT - SEMPRE NO TOPO =====
    col1, col2 = st.columns([4, 1])
    
    # Inicializar contador de input se n√£o existir
    if "input_counter" not in st.session_state:
        st.session_state.input_counter = 0
    
    with col1:
        user_input = st.text_input(
            "Digite sua pergunta aqui...",
            key=f"user_input_{st.session_state.input_counter}",
            placeholder="Digite sua pergunta aqui...",
            label_visibility="collapsed"
        )
    
    with col2:
        send_button = st.button("üì§ Enviar", use_container_width=True, type="primary")
    
    # Processar envio da mensagem (bot√£o ou Enter)
    if (send_button or user_input.strip()) and user_input.strip():
        # Adicionar mensagem do usu√°rio
        st.session_state.messages.append({"role": "user", "content": user_input.strip()})
        
        # Incrementar contador para limpar o campo
        st.session_state.input_counter += 1
        
        # Gerar resposta automaticamente
        with st.spinner("ü§ñ Analisando..."):
            response = st.session_state.chat_ai.generate_response(user_message=user_input.strip(), df=df, analysis_name=analysis_name)
            st.session_state.messages.append({"role": "assistant", "content": response})
        
        # Usar st.rerun() para recarregar a p√°gina e limpar o campo
        st.rerun()
    
    # ===== SUGEST√ïES DE PERGUNTAS - APENAS QUANDO N√ÉO H√Å HIST√ìRICO =====
    if not st.session_state.messages:
        st.markdown("**üí° Sugest√µes de perguntas:**")
        suggestions = st.session_state.chat_ai.suggest_questions(df)
        
        cols = st.columns(2)
        for i, suggestion in enumerate(suggestions[:6]):
            with cols[i % 2]:
                if st.button(suggestion, key=f"suggestion_{i}", use_container_width=True):
                    # Adicionar sugest√£o como mensagem do usu√°rio
                    st.session_state.messages.append({"role": "user", "content": suggestion})
                    
                    # Gerar resposta automaticamente
                    with st.spinner("ü§ñ Analisando..."):
                        response = st.session_state.chat_ai.generate_response(user_message=suggestion, df=df, analysis_name=analysis_name)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    st.rerun()
    
    # ===== LINHA SEPARADORA =====
    st.markdown("---")
    
    # ===== HIST√ìRICO DA CONVERSA - EM CASCATA =====
    if st.session_state.messages:
        st.markdown("### üìù Hist√≥rico da Conversa")
        
        # Mostrar hist√≥rico de mensagens (mais recentes primeiro)
        for i, message in enumerate(reversed(st.session_state.messages)):
            # Determinar emoji baseado no role
            if message["role"] == "user":
                emoji = "üë§"
                role_display = "Usu√°rio"
            else:
                emoji = "ü§ñ"
                role_display = "IA"
            
            # Container para cada mensagem
            with st.container():
                st.markdown(f"**{emoji} {role_display}:**")
                st.markdown(message["content"])
                st.markdown("")  # Espa√ßo entre mensagens
        
        # Bot√µes de a√ß√£o - no final do hist√≥rico
        st.markdown("---")  # Linha separadora
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
        
        with col2:
            if st.button("üìÑ Exportar JSON", use_container_width=True):
                # Exportar conversas para JSON
                json_data = export_conversations_to_json(st.session_state.messages, analysis_name)
                
                # Criar nome do arquivo
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"conversas_{analysis_name.replace(' ', '_')}_{timestamp}.json"
                
                # Criar bot√£o de download
                st.download_button(
                    label="üì• Download JSON",
                    data=json_data,
                    file_name=filename,
                    mime="application/json",
                    use_container_width=True
                )
    else:
        # Quando n√£o h√° hist√≥rico, mostrar mensagem
        st.info("üí¨ Fa√ßa uma pergunta ou escolha uma sugest√£o acima para come√ßar a conversa!")
    
    st.markdown('</div>', unsafe_allow_html=True)
